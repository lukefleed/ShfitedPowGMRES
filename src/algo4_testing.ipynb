{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from scipy.sparse import *\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import norm\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is needed in the algorithm. Note that this is a NON-functioning version, for now it's just a place holder. When algo2_testing will be completed, this will be updated and I'll work on algo4_testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Arnoldi(A,v0,m):\n",
    "    v = v0\n",
    "    beta = norm(v)\n",
    "    v = v/beta\n",
    "    H = sp.sparse.lil_matrix((m+1,m)) \n",
    "    V = sp.sparse.lil_matrix((A.shape[0],m+1))\n",
    "    V[:,0] = v # each column of V is a vector v\n",
    "\n",
    "    for j in range(m):\n",
    "        # print(\"j = \", j)\n",
    "        w = A @ v  \n",
    "        for i in range(j):\n",
    "            tmp = v.T @ w # tmp is a 1x1 matrix, so it's O(1) in memory\n",
    "            H[i,j] = tmp[0,0] \n",
    "            w = w - H[i,j]*v \n",
    "            \n",
    "        H[j+1,j] = norm(w)\n",
    "\n",
    "        if H[j+1,j] == 0:\n",
    "            # print(\"Arnoldi breakdown\")\n",
    "            m = j\n",
    "            v = 0\n",
    "            break\n",
    "        else:\n",
    "            if j < m-1:\n",
    "                v = w/H[j+1,j]\n",
    "                V[:,j+1] = v\n",
    "\n",
    "    # print(j, \" iterations completed\")\n",
    "    # print(\"V = \", V.shape)\n",
    "    # print(\"H = \", H.shape)\n",
    "    # print(\"v = \", v.shape)\n",
    "    # print(\"beta = \", beta)\n",
    "\n",
    "    return V, H, v, beta, j  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 4 testing\n",
    "\n",
    "Still a complete mess. Conceptually and technically wrong. I'll work on it when algo2_testing will be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Algo4(Pt, v, m, a: list, tau, maxit: int, x):\n",
    "    \n",
    "    iter = 1\n",
    "    mv = 0\n",
    "    I = sp.sparse.eye(n, n, format='lil')\n",
    "    r = sp.sparse.lil_matrix((n,1))\n",
    "    res = np.zeros(len(a)) \n",
    "\n",
    "    H_e1 = np.zeros((m+1,1))\n",
    "    H_e1[0] = 1\n",
    "\n",
    "    V_e1 = np.zeros((n,1))\n",
    "    V_e1[0] = 1\n",
    "\n",
    "    s_e1 = np.zeros((len(a),1))\n",
    "    s_e1[0] = 1\n",
    "\n",
    "\n",
    "    def find_k(res):\n",
    "        k = 0\n",
    "        for i in range(len(a)):\n",
    "            if res[i] == max(res):\n",
    "                k = i\n",
    "                break\n",
    "        return k\n",
    "\n",
    "    def compute_gamma(res, a, k):\n",
    "        gamma = sp.sparse.lil_matrix((len(a),1))\n",
    "        for i in range(len(a)):\n",
    "            if i != k:\n",
    "                gamma[i] = (res[i]*a[k])/(res[k]*a[i])\n",
    "            else:\n",
    "                gamma[i] = 0\n",
    "        return gamma\n",
    "\n",
    "    # compute the residual vector\n",
    "    for i in range(len(a)):\n",
    "        r = ((1-a[i])/a[i])*v - ((1/a[i])*I - Pt) @ x\n",
    "        res[i] = a[i]*norm(r)\n",
    "\n",
    "    while max(res) >= tau and iter <= maxit:\n",
    "        k = find_k(res)\n",
    "        gamma = compute_gamma(res, a, k)\n",
    "        # run Arnoldi, with a[k] as the shift\n",
    "        V, H, v, beta, j = Arnoldi((1/a[k])*I - Pt, r, m)\n",
    "\n",
    "        mv = mv + j\n",
    "\n",
    "        # compute y as the minimizer of || beta*e1 - Hy ||_2 using the least squares method\n",
    "        y = sp.sparse.linalg.lsqr(H, beta*H_e1)[0]\n",
    "        tmp = V[:,0:y.shape[0]]\n",
    "\n",
    "        # reshape y to be a column vector\n",
    "        y = y.reshape(y.shape[0],1)\n",
    "        x += tmp @ y\n",
    "\n",
    "        # compute the residual vector\n",
    "        res[k] = a[k]*np.linalg.norm(beta*V_e1 - tmp @ y)\n",
    "        \n",
    "        # for i in range(len(a)) but not k\n",
    "        for i in range(len(a)):\n",
    "            if i != k and res[i] >= tau:\n",
    "                H = H + ((1-a[i])/a[i] - (1-a[k])/a[k])*sp.sparse.eye(H.shape[0], H.shape[1], format='lil')\n",
    "\n",
    "                # solve y and gamma[i] from [H z] = [y gamma[i]]^T = gamma[i]*e1*beta\n",
    "                z = beta*H_e1 - H.dot(y)\n",
    "                A_tmp = sp.sparse.hstack([H, z])    \n",
    "                b_tmp = gamma * beta \n",
    "\n",
    "                # make b_tmp a column vector\n",
    "                b_tmp = b_tmp.reshape(b_tmp.shape[0],1)\n",
    "                # add zeros to the end of b_tmp until it has the same number of rows as A_tmp\n",
    "                b_tmp = sp.sparse.vstack([b_tmp, sp.sparse.lil_matrix((A_tmp.shape[0]-b_tmp.shape[0],1))])\n",
    "\n",
    "\n",
    "                # solve the system, without using the least squares method\n",
    "                # CONVERT TO CSC FORMAT TO USE SPARSE SOLVERS\n",
    "                A_tmp = A_tmp.tocsc()\n",
    "\n",
    "                result = sp.sparse.linalg.spsolve(A_tmp, b_tmp)[0]\n",
    "                print(\"result:\", result.shape)\n",
    "                                \n",
    "                \n",
    "                # split the result into y and gamma\n",
    "                y = result[0:y.shape[0]]\n",
    "                gamma = result[y.shape[0]:]\n",
    "\n",
    "                # update x\n",
    "                x = x + tmp @ y\n",
    "                # update residual\n",
    "                res = (a[i]/a[k])*res*gamma[k]\n",
    "\n",
    "        iter = iter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_264197/102804730.py:12: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(G)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: ()\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_264197/102804730.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mPt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# run the algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mAlgo4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_264197/2668036735.py\u001b[0m in \u001b[0;36mAlgo4\u001b[0;34m(Pt, v, m, a, tau, maxit, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;31m# split the result into y and gamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "# test the algorithm\n",
    "n = 100\n",
    "m = 110\n",
    "maxit = 100\n",
    "tau = 1e-6\n",
    "a = [0.85, 0.9, 0.95, 0.99]\n",
    "x = sp.sparse.lil_matrix((n,1))\n",
    "x[0,0] = 1\n",
    "# generate a random graph\n",
    "G = nx.gnp_random_graph(n, 0.1, seed=1, directed=True)\n",
    "# generate a random matrix\n",
    "A = nx.adjacency_matrix(G)\n",
    "# generate a random vector\n",
    "v = sp.sparse.rand(n, 1, density=0.1, format='lil')\n",
    "# compute the power iteration matrix\n",
    "Pt = A.T\n",
    "# run the algorithm\n",
    "Algo4(Pt, v, m, a, tau, maxit, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
